### Reading for this week:

> Burton, A. W. (1991). Parallel processing in large-scale simulation: motivation and methods. Computing & Control Engineering Journal, 2(2), 74-79.









## What is parallel computing?

Parallel computing is the act of using more than a single core of your processor. Most processors have multiple cores (4-core, 8-core, 16-core, etc.). When a process is run, it could occur sequentially (e.g., think of a for loop, going through each index of the loop and iterating forward). The idea of parallel processing is to distribute tasks and data to multiple cores in order to shorten the time it takes to run an analysis (or do the task). Conceptually, think of the for loop, but instead of doing things sequentially, each task is sent to a different CPU core. This type of task, where each task can be broken into a discrete unit, is often called "embarrassingly parallel". I have no idea why, but it is likely somehow linked to the dismissive and toxic culture that permeates tech. It does point to something though. Some tasks can be parallelized, and some cannot. Many tasks can be parallelized at different points, with huge implications to total time for the task. For instance, if you have a model that you would like to run with 1000 parameterizations, and each model is run 10 times, it is possible to parallelize at two different levels. We could parallelize the 1000 parameters, or we could parallelize the model running 10 times. We cannot parallelize both, because it does not work that like that. Thinking about where to parallelize will give you a better idea of what the computer is doing, and how to manage memory and resources.




It may be hard to mentally justify the switch from running something on a single CPU core versus making it amenable to parallel processing, especially when dealing with data sizes and tasks that run fairly quickly. But at times, computations can be:

+ cpu-bound: Take too much cpu time 
+ memory-bound: Take too much memory
+ I/O-bound: Take too much time to read/write from disk
+ network-bound: Take too much time to transfer


`R` is dumb and has to hold everything in memory, so memory-bound processes are not ideal for parallelization in `R` (there are some circumstances where this is not true). The main constraint that you may run into is processes that are cpu-bound.






## Why is it useful?

The time speed up is probably the most useful aspect of parallel computing. At some point in the future, given the increasing availability of data and complexity of models, you will likely encounter a task that you may need to parallelize, or a task that requires too much memory to run on your local machine. In the latter case, you may have access to a cluster, which is essentially a bunch of machines networked together with a decent amount of memory and processing power. But while the memory is available on these machines, you will also have to write the code to be parallelized. Single-core jobs are not really run on clusters, as the power of the cluster really comes from the ability to do many distributed tasks. 






## How do we do it in R?

So hopefully I have convinced you that parallel processing is a useful skill and is sometimes (oftentimes in my limited experience) essential. So now we want to know how to do it in `R`. There are a number of packages for performing parallel computing tasks, but they mostly boil down to the `parallel` package. This package ships with base `R`, and has functions that may appear really familiar based on earlier lectures. For instance, the `clusterApplyLB` function is an `apply` statement that works on a cluster. 




### setting up your cluster

Now we will make a cluster. Your local machine almost certainly has more than 1 core. Many phones have more than one core. When you hear things like "quad core CPU", this means that the processor (CPU) has 4 cores. To see how many cores you have access to on your machine, you can use the `detect.cores` function


```{r}
install.packages('parallel')
library(parallel)
```


```{r}

parallel::detectCores()

```

The number this returns will depend on whatever machine the document was compiled on. If I am at home, it will likely return "8", as I have a quad-core CPU which is hyperthreaded, so it has 4 physical cores, but 8 virtual cores. If I am on my laptop, it will return "4". If I unnecessarily compile this on the cluster here at Louisiana State University, it might say anywhere between 1 and 64 (or more). 



So now we will construct a cluster of 2 nodes. This should hypothetically cut the time our task takes in half, though this ignores the overhead of moving data around to different cores.




```{r}

cl <- parallel::makeCluster(2)
cl

```


Now we have our cluster. Let us do a simple benchmark test using the `clusterApplyLB` function. The task is to wait `i` seconds where `i` is the vector `c(1,2,3,4,5)`. 


```{r}

system.time(
	for(i in 1:5){
		Sys.sleep(i)
	}
)


system.time(
	parallel::clusterApplyLB(cl, 1:5, function(x){
		Sys.sleep(x)
	})
)

```



The first function, which is not parallelized, takes 15 seconds to run. This makes sense, as `sum(1:5)` is 15. Meanwhile, the parallel code takes around half the time, because it can divide the "waiting" between 2 cores. So one core waits for 1 second while the other waits for 2, and as soon as the first core is done waiting one second, it starts to wait 3 seconds. This is called "load balancing", as the individual processes may take different amounts of time. If we were to assume that each parallel process takes the same amount of time, we could enter a situation where some cores are not doing anything while the longer-running processes finishes (this is not ideal). 





After we are done with a parallel process, we have to properly shut our cluster down. 


```{r, eval=FALSE}

parallel::stopCluster(cl)

```


Above in the chunk options for this code block, I set `eval=FALSE` so that the `cl` object could still be used by processes below. 








### Making sure our parallel code is reproducible.

Parallel code is subject to worry about reproducibility just as much as non-parallel code. If we make draws from a distribution, we need to be sure to set the seed with `set.seed()`. In a parallel context, this can be in the function if we have a clear integer index to use. For instance, the code below draws a random uniform variable of length between 1 and 5. We provide the vector `c(1,2,3,4,5)` to the function, so we can use these integers to set the seed.



Make the cluster (assuming we stopped the cluster above).

```{r}

cl <- parallel::makeCluster(2)
cl

```



```{r}

parallel::clusterApplyLB(cl, 1:5, 
	function(x){
		set.seed(x)
		runif(x)
	}
)

```


This is a rare exception to what your code will likely look like. If you have a probabilistic component to each process you would like to run in parallel, consider handing the parallel function an index and using the index to specify a row of a data.frame containing relevant parameters. For instance, using the above example, what if we wanted to draw from a uniform distribution, but we wanted a different number of values, a different minimum range, and a different maximum range of the distribution?



```{r}

parms <- data.frame(index=1:5, 
	numValues=c(1,2,1,3,5),
	minRange=c(0,1,2,1,0),
	maxRange=c(5,8,11,8,5))

```


```{r, eval=FALSE}

parallel::clusterApplyLB(cl, parms$index, 
	function(x){
		set.seed(parms$index)
		runif(parms$numValues[x], 
			min=parms$minRange[x],
			max=parms$maxRange[x]
		)
	}
)

```


This would error out, saying that `parms` is not found. But we can use `ls()` and see that parms is in the workspace. This is a common issue. `parms` may be the workspace, but each individual core needs access to the `parms` data.frame, so being in the global workspace does not really matter. This is also true of `R` functions in other packages, so the use of the `require()` function in your code may be necessary to make sure `R` package functionality is accessible across all cores. This is why we use the line: 



```{r, eval=FALSE}

parallel::clusterExport(cl=cl, list('parms'))

```


to make sure that the cluster has access to the data.frame `parms`. 







The `dplyr` package also allows some parallelization functions of apply type functions.


```{r}

install.packages('doMC')
install.packages('plyr')

```


```{r}

lst <- lapply(1:1000, function(x){runif(10000)})
doMC::registerDoMC(4)

# not parallel
system.time(plyr::ldply(lst, .parallel=FALSE, .fun=mean))

# parallel
system.time(plyr::ldply(lst, .parallel=TRUE, .fun=mean))

```

Now we have finished with the cluster `cl` and we can stop it using the `parallel::stopCluster` function. 

```{r}

parallel::stopCluster(cl)

```













**Practice**: 

Remember the logistic model we went over before? 


```{r}
logisticGrowth <- function(n, r, k){
  n*exp(r*(1-(n / k)))
}


logisticDynamics <- function(n,r,k, steps=100){
  ret <- c()
  ret[1] <- n
  if(length(r) == 1){
    r <- rep(r, steps)
  }
  for(i in 1:(steps-1)){
    ret[i+1] <- logisticGrowth(ret[i], r[i], k)
  }
  return(ret)
}
```



Write code that runs logisticDynamics in parallel, running out the dynamics of the logistic model for 100 steps, but starting with population sizes between 1 and 1000. 


```{r}



```





Do the same thing, but with a for loop. 

```{r}





```



Wrap both approaches in a `system.time()` call to explore how long each takes. 






> Read this for Thursday: https://cyclismo.org/tutorial/R/probability.html 
> Roger Peng's book may also help for this: https://bookdown.org/rdpeng/rprogdatascience/simulation.html#generating-random-numbers

> For more info on parallel computing, gentle introduction here https://bookdown.org/rdpeng/rprogdatascience/parallel-computation.html











## Line profiling


Using `system.time()` is one way to do line profiling, but it's a bit coarse, in that the entire expression is wrapped around the `system.time()` call. But what if want to know not only how long something takes, but also what constituent parts of the code are running fastest/slowest? We can use built-in line profiling tools like `Rprof` to address this. 


```{r}
Rprof()     ## Turn on the profiler
## ALL YOUR CODE 
Rprof(NULL) ## Turn off the profiler 
```


```{r}
summaryRprof()
```











---

## Connecting and running code on remote machines 

SSH stands for secure shell, a way to remotely connect to computers or servers. These machines are typically always on, have more memory than your local machine, or you just want to be able to run code for longer periods of time without taxing your local machine and not turning it off. 

Let's go over some basics of `ssh` and how to incorporate these tools into your workflow. If we have time, we can also sign up for the local U of South Carolina cluster and work through job submission. This is a similar process (`ssh`), but computing clusters (since they have many many users) need to have a job manager (e.g., slurm) which requires the user to write a shell script that specifies how much resources, which resources, and for how long. 







### ssh 

First, you may need to install `ssh` on your local machine. 

> For Windows users, this may (or may not) require you download PuTTY. Or you may be able to do this process through the Window subsystem for linux (wsl). 


```{ }
sudo apt update
sudo apt install openssh-server
sudo systemctl status ssh

```

if you the above final line of code does not result in something that looks like it's running ssh service, then you can manually enable it by issuing the command

```
sudo systemctl enable --now ssh
```

For Windows users, the above **should** work if you remove the `sudo` bits (since you are a root user). But we can work through some errors in class potentially. For Mac users, you should have ssh already ready to go, but if not, try the following commands

```
sudo systemsetup -getremotelogin
sudo systemsetup -setremotelogin on
```

where the top line should check if remote login is enabled, and the second line should turn it on if it is not already on. 


The structure of an ssh call is the following

```
ssh USERNAME@IP.ADDRESS
```

An example of this would be something like


```
ssh guest@10.80.193.202
```

Note that you must be connected to the same network in this case to ssh. This means that if you are connecting from off campus, you will need to use the campus VPN to remote into any machine. More on this for different operating systems can be found here: 

https://sc.edu/about/offices_and_divisions/division_of_information_technology/security/training/remote_working_security/index.php














### terminal multiplexers 

It's a cool name, and there are a few different options. I use `screen`, but another great option is `tmux`. The end goal is the same, to allow for a single terminal window to be partitioned out into multiple terminal sessions, and _most importantly_ to be able to detach from terminal sessions. 

This is important, as it allows you to remote into a computer, start running code, and then break the connection without causing the code to stop running. Then you can remote back into the machine and re-attach to the running terminal session. We'll use `screen` below to show the utility in this. 



screen may be pre-installed. If not, install it. 

```
sudo apt update
sudo apt install screen
```


Now let's explore how to use `screen` on your local machine. 

```
screen 
```

When you issue the screen command, not much should change, but you are asked to hit enter (I believe) and then you'll be in the screen session, meaning you can detach using `cntrl+a+d` or `screen -D`. This may close your terminal screen, but it's still a terminal session that is there, it's just now detached. You can re-attach to the terminal session using `screen -r ` followed by the session name. To see the ongoing screen sessions, you can use `screen -ls`. The session name starts with a number, so if you wanted to reattach to that particular screen instance (and assuming you had more than 1 screen instance running), you would need to specify which screen instance to re-attach to using `screen -r 30485094.pts-1.office` where the last bit calls the specific session. 

It's good practice to start `screen` instances with an informative session name. You can do this when starting a screen session 


```
screen -S test 
```

Now consider how you would use this to run an analysis. You could create a screen instance, start running some long running code in R, and then detach from the session, close your computer, and know that your analysis was safely running on the remote machine. 


But here we run into file management issues, potentially. The remote machine does not have the same files as you have on your local machine, meaning that you will have to move files back and forth between remote and local machines, or always run code on a remote machine by first pulling a git repository from GitHub. This second approach is probably best, to avoid multiple copies of the same files being on both local and remote machines. However, you may encouter a situation where the result of an analysis is too big to version on GitHub, meaning you run the analysis, save the necessary bits, and then cannot push back to GitHub from the remote machine. You can use `scp` to move files between remote and local machines, in this case. 

```
scp localFileSource Destination
```

So let's say I want to move something from my local machine to the remote machine. I am logged into my local machine, and I would issue a command like 

```
scp file.RData tad@10.90.123.123:
```

This would move `file.RData` to the remote machine, and place the file in the home directory (or whatever is the default directory of the remote machine). Moving a file from a remote machine is possible as well from your local machine, by specifying the source as the remote machine

```
scp tad@10.90.123.123:file.RData /home/

```

where this would move `file.RData` from the remote machine to the local machine, specifically in the `/home/` directory (be sure that whatever path you tell it actually exists, or else it'll error out). 




























---


# Assorted tips and tricks from someone who fails often

These will likely mostly center around `R`, but are essentially things that I have learned the hard way while programming my way to where I am now. 


### keep your analytical pipeline organized and consistent between projects

I give all my projects a name in lowerCamelCase, and every project contains the same folders. Keeping this level of organization has allowed me to maintain and push along multiple projects simultaneously. This is not to say that your analytical workflow should not change over time, as it will almost undoubtedly change (and should change). Do not be the equivalent of a person using Excel/SPSS/etc. and refusing to change because it is what you feel most familiar with. 






### create your own R package

creating an `R` package, either for distribution or just for personal use, is a really rewarding experience. It forces you to document code, handle errors effectively, and write efficient code (since these are functions that will either be released to the public or used by you often enough to be optimized). 





### use relative paths!

bad: setwd('/home/tad/projectFolder/analysis')

good: setwd('analysis') 







### force yourself to version your projects 

try to mentally remind yourself that every change you make to the project is reason enough to add-commit-push that to Github for proper versioning. This allows you to track your progress, and ensures that you have a backup of your project in case something happens to your local copy.






### read more about open source and open access

there are a lot of issues around reproducibility and open science that we did not cover here. Related to reproducibility is the open accessibility of code and data. It is worth reading about open access concepts and approaches to doing science.





### consider giving Linux a chance

It is a neat OS that has all the tools that you may have struggled to install and use pretty much out of the box. Plus, it is open source.




### consider giving LaTeX a chance

LaTeX is a typesetting language, of which I am a huge fan. It produces beautifully typeset documents, auto-formats references, and handles equations and formatting incredibly well. 





### write modular code

Do not write the same code twice. Write a general function that can be applied to a diverse set of inputs.




### do not put spaces in any file/folder name

Spaces are dumb, and different machines handle them differently. Best to avoid them altogether. 







### think about data format and legacy issues

Some data formats may last a long time (csv is unlikely to really change), while others are either proprietary (not great for reproducibility) or are now defunct. Keeping your data in a format that is as stable as possible goes a long way to helping keep your analyses reproducible. xls is a terrible format for data. 







